pip install s3fs

import s3fs

fs = s3fs.S3FileSystem(anon=True) # with all public bucket access

fs = s3fs.S3FileSystem(anon=False) 


fs.ls(“…”)


fs.touch(“…”/”test.txt”)


  json.dump(model_options, s3.open(f"{BUCKET_NAME}/options_{model_options['name'] + str(np.random.randint(10000))}.json",'w'))



# your data preprocessing...

  s3 = s3fs.S3FileSystem(anon=False)
  df = pd.DataFrame(data={"foo":[0]})
  print(df)

  with s3.open(f"{BUCKET_NAME}/data_bow_limit40000.csv",'w') as f:
      df.to_csv(f)